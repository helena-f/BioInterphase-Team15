{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Do we want the quadrants still? I can work on it, just ran into issues and have not finished it yet."],"metadata":{"id":"kCApEHKeDPCo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKO0AFpa7HLq"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from scipy.interpolate import griddata\n","import numpy as np\n","import pandas as pd\n","\n","def plot_hab_heatmap_by_state(file_path, state_name, year, month, resolution=100):\n","    \"\"\"\n","    Plots a heat map of HAB likelihood based on cell counts for a specific state and time.\n","\n","    Parameters: or\n","        file_path (str): Path to the dataset file.\n","        state_name (str): Name of the state (e.g., \"California\").\n","        year (int): Year of interest.\n","        month (int): Month of interest (1-12).\n","        resolution (int): Resolution of the grid for the heat map.\n","\n","    Returns:\n","        None: Displays the heat map.\n","    \"\"\"\n","    # Load the dataset\n","    data = pd.read_csv(file_path)\n","\n","    # Ensure SAMPLE_DATE is in datetime format\n","    data['SAMPLE_DATE'] = pd.to_datetime(data['SAMPLE_DATE'], errors='coerce')\n","\n","    # Filter by year and month\n","    data = data[(data['SAMPLE_DATE'].dt.year == year) & (data['SAMPLE_DATE'].dt.month == month)]\n","\n","    if data.empty:\n","        print(f\"No data available for {state_name} in {month}/{year}.\")\n","        return\n","\n","    # Filter by state\n","    state_data = data[data['STATE_ID'].str.contains(state_name, case=False, na=False)]\n","\n","    if state_data.empty:\n","        print(f\"No data available for {state_name}.\")\n","        return\n","\n","    # Extract relevant data for interpolation\n","    latitudes = state_data['LATITUDE']\n","    longitudes = state_data['LONGITUDE']\n","    cell_counts = state_data['CELLCOUNT']\n","\n","    # Remove rows with missing or invalid cell counts\n","    valid_data = state_data[cell_counts.notnull()]\n","    latitudes = valid_data['LATITUDE']\n","    longitudes = valid_data['LONGITUDE']\n","    cell_counts = valid_data['CELLCOUNT']\n","\n","    if cell_counts.empty:\n","        print(f\"No valid cell count data available for {state_name}.\")\n","        return\n","\n","    # Create a grid for interpolation\n","    lat_min, lat_max = latitudes.min(), latitudes.max()\n","    lon_min, lon_max = longitudes.min(), longitudes.max()\n","    grid_lat = np.linspace(lat_min, lat_max, resolution)\n","    grid_lon = np.linspace(lon_min, lon_max, resolution)\n","    grid_lat, grid_lon = np.meshgrid(grid_lat, grid_lon)\n","\n","    # Interpolate cell count data onto the grid\n","    grid_hab = griddata(\n","        points=(latitudes, longitudes),\n","        values=cell_counts,\n","        xi=(grid_lat, grid_lon),\n","        method='linear'\n","    )\n","\n","    # Plot the heat map\n","    plt.figure(figsize=(12, 8))\n","    plt.contourf(grid_lon, grid_lat, grid_hab, levels=50, cmap='YlOrRd')\n","    plt.colorbar(label=\"Cell Count (HAB Likelihood)\")\n","    plt.scatter(longitudes, latitudes, c='blue', s=10, label='Data Points', alpha=0.6)\n","    plt.title(f\"HAB Heat Map: {state_name} - {month}/{year}\")\n","    plt.xlabel(\"Longitude\")\n","    plt.ylabel(\"Latitude\")\n","    plt.legend()\n","    plt.grid()\n","    plt.show()"]},{"cell_type":"code","source":["\n","# Example usage:\n","plot_hab_heatmap_by_state(\"(final)cleaned_habsos_data_v3.csv\", state_name=\"FL\", year=2013, month=9)\n","import folium\n","from folium.plugins import HeatMap\n","import pandas as pd\n","\n","def plot_hab_heatmap_on_map_fixed(file_path, state_name, year, month):\n","    \"\"\"\n","    Plots a heat map of HAB likelihood on a map of a specific state and time.\n","\n","    Parameters:\n","        file_path (str): Path to the dataset file.\n","        state_name (str): Name of the state (e.g., \"Florida\").\n","        year (int): Year of interest.\n","        month (int): Month of interest (1-12).\n","\n","    Returns:\n","        folium.Map: A folium map object with the heat map overlay.\n","    \"\"\"\n","    # Load the dataset\n","    data = pd.read_csv(file_path)\n","\n","    # Ensure SAMPLE_DATE is in datetime format\n","    data['SAMPLE_DATE'] = pd.to_datetime(data['SAMPLE_DATE'], errors='coerce')\n","\n","    # Filter by year and month\n","    data = data[(data['SAMPLE_DATE'].dt.year == year) & (data['SAMPLE_DATE'].dt.month == month)]\n","    print(f\"Data after year/month filter: {data.shape[0]} rows\")\n","\n","    if data.empty:\n","        print(f\"No data available for {state_name} in {month}/{year}.\")\n","        return None\n","\n","    # Filter by state\n","    state_data = data[data['STATE_ID'].str.contains(state_name, case=False, na=False)]\n","    print(f\"Data after state filter: {state_data.shape[0]} rows\")\n","\n","    if state_data.empty:\n","        print(f\"No data available for {state_name}.\")\n","        return None\n","\n","    # Check for missing CELLCOUNT\n","    print(f\"Missing CELLCOUNT values: {state_data['CELLCOUNT'].isnull().sum()} rows\")\n","\n","    # Extract relevant data (only rows with valid CELLCOUNT)\n","    valid_data = state_data[state_data['CELLCOUNT'].notnull()]\n","    print(f\"Data after CELLCOUNT filter: {valid_data.shape[0]} rows\")\n","\n","    # If there are no valid data points, return None\n","    if valid_data.empty:\n","        print(f\"No valid cell count data available for {state_name}.\")\n","        return None\n","\n","    # Adjust longitude if it exceeds 180 (convert to -180 to 180 range)\n","    state_data = state_data.copy()  # Avoid SettingWithCopyWarning\n","    state_data.loc[state_data['LONGITUDE'] > 180, 'LONGITUDE'] -= 360\n","\n","    # Check for valid latitude and longitude ranges\n","    lat_min, lat_max = valid_data['LATITUDE'].min(), valid_data['LATITUDE'].max()\n","    lon_min, lon_max = valid_data['LONGITUDE'].min(), valid_data['LONGITUDE'].max()\n","    print(f\"Lat range: {lat_min} to {lat_max}, Lon range: {lon_min} to {lon_max}\")\n","\n","    # Debug: Show a few of the latitude and longitude values\n","    print(f\"Sample latitudes: {valid_data['LATITUDE'].head()}\")\n","    print(f\"Sample longitudes: {valid_data['LONGITUDE'].head()}\")\n","\n","    # Create a base map centered on the state's bounding box\n","    map_center = [(lat_min + lat_max) / 2, (lon_min + lon_max) / 2]\n","    print(f\"Map center: {map_center}\")\n","\n","    # Set a zoom level based on the data range (adjust as necessary)\n","    zoom_level = 7 if (lat_max - lat_min) > 1 else 10\n","    base_map = folium.Map(location=map_center, zoom_start=zoom_level)\n","\n","    # Prepare heat map data\n","    heat_data = [\n","        [row['LATITUDE'], row['LONGITUDE'], row['CELLCOUNT']]\n","        for _, row in valid_data.iterrows()\n","    ]\n","\n","    # Add the heat map to the base map\n","    HeatMap(heat_data, radius=10, blur=15, max_zoom=1, gradient={0.2: \"blue\", 0.5: \"lime\", 1: \"red\"}).add_to(base_map)\n","\n","    # Return the map object\n","    return base_map\n","\n","# Example usage:\n","map_obj = plot_hab_heatmap_on_map_fixed(\"(final)cleaned_habsos_data_v3.csv\", \"FL\", 2013, 9)\n","map_obj.save(\"Florida_HAB_Heatmap_Fixed5.html\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"GD-VUkFB7hBH","executionInfo":{"status":"error","timestamp":1733169235917,"user_tz":300,"elapsed":298,"user":{"displayName":"Rachel Weiss","userId":"15853572085964370226"}},"outputId":"a26d25f2-7b2f-4f69-cc1d-fd4e01c3f65c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '(final)cleaned_habsos_data_v3.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6779fbfb8483>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_hab_heatmap_by_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(final)cleaned_habsos_data_v3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"FL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeatMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-2cb0f1d833d3>\u001b[0m in \u001b[0;36mplot_hab_heatmap_by_state\u001b[0;34m(file_path, state_name, year, month, resolution)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Ensure SAMPLE_DATE is in datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '(final)cleaned_habsos_data_v3.csv'"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from scipy.interpolate import griddata\n","import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","\n","# to mount Google Drive\n","drive.mount('/content/drive')\n","\n","\n","def plot_hab_heatmap_by_state(file_path, state_name, year, month, resolution=100):\n","    \"\"\"\n","    Plots a heat map of HAB likelihood based on Predicted_CELLCOUNT for a specific state and time.\n","\n","    Parameters:\n","        file_path (str): Path to the dataset file.\n","        state_name (str): Name of the state (e.g., \"California\").\n","        year (int): Year of interest.\n","        month (int): Month of interest (1-12).\n","        resolution (int): Resolution of the grid for the heat map.\n","\n","    Returns:\n","        None: Displays the heat map.\n","    \"\"\"\n","    # Load the dataset\n","    data = pd.read_csv(file_path)\n","\n","    # Ensure SAMPLE_DATE is in datetime format\n","    data['SAMPLE_DATE'] = pd.to_datetime(data['SAMPLE_DATE'], errors='coerce')\n","\n","    # Filter by year and month\n","    data = data[(data['SAMPLE_DATE'].dt.year == year) & (data['SAMPLE_DATE'].dt.month == month)]\n","\n","    if data.empty:\n","        print(f\"No data available for {state_name} in {month}/{year}.\")\n","        return\n","\n","    # Filter by state\n","    state_data = data[data['STATE_ID'].str.contains(state_name, case=False, na=False)]\n","\n","    if state_data.empty:\n","        print(f\"No data available for {state_name}.\")\n","        return\n","\n","    # Extract relevant data for interpolation\n","    latitudes = state_data['LATITUDE']\n","    longitudes = state_data['LONGITUDE']\n","\n","    # Ensure 'Predicted_CELLCOUNT' column exists\n","    for col in ['True_CELLCOUNT', 'Predicted_CELLCOUNT']:\n","        if col not in state_data.columns:\n","            print(f\"Column '{col}' not found in the dataset.\")\n","            return\n","\n","\n","    # Remove rows with missing or invalid cell counts\n","    valid_data = state_data[cell_counts.notnull()]\n","    latitudes = valid_data['LATITUDE']\n","    longitudes = valid_data['LONGITUDE']\n","    cell_counts = valid_data['Predicted_CELLCOUNT']\n","\n","    if cell_counts.empty:\n","        print(f\"No valid data in 'Predicted_CELLCOUNT' for {state_name}.\")\n","        return\n","\n","    # Create a grid for interpolation\n","    lat_min, lat_max = latitudes.min(), latitudes.max()\n","    lon_min, lon_max = longitudes.min(), longitudes.max()\n","    grid_lat = np.linspace(lat_min, lat_max, resolution)\n","    grid_lon = np.linspace(lon_min, lon_max, resolution)\n","    grid_lat, grid_lon = np.meshgrid(grid_lat, grid_lon)\n","\n","    # Interpolate cell count data onto the grid\n","    grid_hab = griddata(\n","        points=(latitudes, longitudes),\n","        values=cell_counts,\n","        xi=(grid_lat, grid_lon),\n","        method='linear'\n","    )\n","\n","    # Plot the heat map\n","    plt.figure(figsize=(12, 8))\n","    plt.contourf(grid_lon, grid_lat, grid_hab, levels=50, cmap='YlOrRd')\n","    plt.colorbar(label=\"Predicted_CELLCOUNT (HAB Likelihood)\")\n","    plt.scatter(longitudes, latitudes, c='blue', s=10, label='Data Points', alpha=0.6)\n","    plt.title(f\"HAB Heat Map: {state_name} - {month}/{year} (Predicted_CELLCOUNT)\")\n","    plt.xlabel(\"Longitude\")\n","    plt.ylabel(\"Latitude\")\n","    plt.legend()\n","    plt.grid()\n","    plt.show()\n","\n","# Example usage\n","file_path = '/content/drive/MyDrive/Team15-Biointerphase/Dataset/model_predictions.csv'\n","plot_hab_heatmap_by_state(file_path, 'FL', 2013, 9, resolution=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"id":"bHOoDbFVEfg4","executionInfo":{"status":"error","timestamp":1733188516492,"user_tz":300,"elapsed":17941,"user":{"displayName":"Rachel Weiss","userId":"15853572085964370226"}},"outputId":"9c1d95aa-6b02-4d2f-bd96-11ab18a06b71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"KeyError","evalue":"'SAMPLE_DATE'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'SAMPLE_DATE'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ce62afa30bfc>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Team15-Biointerphase/Dataset/model_predictions.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mplot_hab_heatmap_by_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-ce62afa30bfc>\u001b[0m in \u001b[0;36mplot_hab_heatmap_by_state\u001b[0;34m(file_path, state_name, year, month, resolution)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Ensure SAMPLE_DATE is in datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SAMPLE_DATE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SAMPLE_DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Filter by year and month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'SAMPLE_DATE'"]}]},{"cell_type":"code","source":["def plot_hab_heatmaps(file_path, state_name, year, month, resolution=100):\n","    \"\"\"\n","    Plots two heat maps: one for True_CELLCOUNT and one for Predicted_CELLCOUNT.\n","\n","    Parameters:\n","        file_path (str): Path to the dataset file.\n","        state_name (str): Name of the state (e.g., \"California\").\n","        year (int): Year of interest.\n","        month (int): Month of interest (1-12).\n","        resolution (int): Resolution of the grid for the heat map.\n","\n","    Returns:\n","        None: Displays the heat maps.\n","    \"\"\"\n","    # Load the dataset\n","    data = pd.read_csv(file_path)\n","\n","    # Ensure SAMPLE_DATE is in datetime format\n","    data['SAMPLE_DATE'] = pd.to_datetime(data['SAMPLE_DATE'], errors='coerce')\n","\n","    # Filter by year and month\n","    data = data[(data['SAMPLE_DATE'].dt.year == year) & (data['SAMPLE_DATE'].dt.month == month)]\n","\n","    if data.empty:\n","        print(f\"No data available for {state_name} in {month}/{year}.\")\n","        return\n","\n","    # Filter by state\n","    state_data = data[data['STATE_ID'].str.contains(state_name, case=False, na=False)]\n","\n","    if state_data.empty:\n","        print(f\"No data available for {state_name}.\")\n","        return\n","\n","    # Ensure columns exist\n","    for col in ['True_CELLCOUNT', 'Predicted_CELLCOUNT']:\n","        if col not in state_data.columns:\n","            print(f\"Column '{col}' not found in the dataset.\")\n","            return\n","\n","    # Create a grid for interpolation\n","    latitudes = state_data['LATITUDE']\n","    longitudes = state_data['LONGITUDE']\n","    lat_min, lat_max = latitudes.min(), latitudes.max()\n","    lon_min, lon_max = longitudes.min(), longitudes.max()\n","    grid_lat = np.linspace(lat_min, lat_max, resolution)\n","    grid_lon = np.linspace(lon_min, lon_max, resolution)\n","    grid_lat, grid_lon = np.meshgrid(grid_lat, grid_lon)\n","\n","    for col in ['True_CELLCOUNT', 'Predicted_CELLCOUNT']:\n","        # Remove rows with missing or invalid data\n","        valid_data = state_data[state_data[col].notnull()]\n","        latitudes = valid_data['LATITUDE']\n","        longitudes = valid_data['LONGITUDE']\n","        values = valid_data[col]\n","\n","        # Interpolate data onto the grid\n","        grid_hab = griddata(\n","            points=(latitudes, longitudes),\n","            values=values,\n","            xi=(grid_lat, grid_lon),\n","            method='linear'\n","        )\n","\n","        # Plot the heat map\n","        plt.figure(figsize=(12, 8))\n","        plt.contourf(grid_lon, grid_lat, grid_hab, levels=50, cmap='YlOrRd')\n","        plt.colorbar(label=f\"{col} (HAB Likelihood)\")\n","        plt.scatter(longitudes, latitudes, c='blue', s=10, label='Data Points', alpha=0.6)\n","        plt.title(f\"HAB Heat Map ({col}): {state_name} - {month}/{year}\")\n","        plt.xlabel(\"Longitude\")\n","        plt.ylabel(\"Latitude\")\n","        plt.legend()\n","        plt.grid()\n","        plt.show()\n","\n","\n"],"metadata":{"id":"gewnss5nE7H9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import matplotlib.pyplot as plt\n","import geopandas as gpd\n","from scipy.interpolate import griddata\n","import numpy as np\n","import pandas as pd\n","\n","url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n","\n","gdf = gpd.read_file(url)\n","\n","def plot_hab_heatmap_by_state_on_map(file_path, state_name, year, month, resolution=100):\n","    \"\"\"\n","    Plots a heat map of HAB likelihood based on cell counts for a specific state and time, overlayed on a world map.\n","\n","    Parameters:\n","        file_path (str): Path to the dataset file.\n","        state_name (str): Name of the state (e.g., \"California\").\n","        year (int): Year of interest.\n","        month (int): Month of interest (1-12).\n","        resolution (int): Resolution of the grid for the heat map.\n","\n","    Returns:\n","        None: Displays the heat map overlayed on the world map.\n","    \"\"\"\n","    # Load the dataset\n","    data = pd.read_csv(file_path)\n","\n","    # Ensure SAMPLE_DATE is in datetime format\n","    data['SAMPLE_DATE'] = pd.to_datetime(data['SAMPLE_DATE'], errors='coerce')\n","\n","    # Filter by year and month\n","    data = data[(data['SAMPLE_DATE'].dt.year == year) & (data['SAMPLE_DATE'].dt.month == month)]\n","\n","    if data.empty:\n","        print(f\"No data available for {state_name} in {month}/{year}.\")\n","        return\n","\n","    # Filter by state\n","    state_data = data[data['STATE_ID'].str.contains(state_name, case=False, na=False)]\n","\n","    if state_data.empty:\n","        print(f\"No data available for {state_name}.\")\n","        return\n","\n","    # Extract relevant data for interpolation\n","    latitudes = state_data['LATITUDE']\n","    longitudes = state_data['LONGITUDE']\n","    cell_counts = state_data['CELLCOUNT']\n","\n","    # Remove rows with missing or invalid cell counts\n","    valid_data = state_data[cell_counts.notnull()]\n","    latitudes = valid_data['LATITUDE']\n","    longitudes = valid_data['LONGITUDE']\n","    cell_counts = valid_data['CELLCOUNT']\n","\n","    if cell_counts.empty:\n","        print(f\"No valid cell count data available for {state_name}.\")\n","        return\n","\n","    # Adjust latitudes from [0, 180] to [-90, 90]\n","    latitudes = latitudes - 90  # Shift latitudes from 0-180 to -90 to 90\n","\n","    # Adjust longitudes from [0, 360] to [-180, 180]\n","    print(longitudes)\n","    longitudes = longitudes-360  # Shift longitudes from 0-360 to -180 to 180\n","\n","\n","    # Create a grid for interpolation\n","    lat_min, lat_max = latitudes.min(), latitudes.max()\n","    lon_min, lon_max = longitudes.min(), longitudes.max()\n","    grid_lat = np.linspace(lat_min, lat_max, resolution)\n","    grid_lon = np.linspace(lon_min, lon_max, resolution)\n","    grid_lat, grid_lon = np.meshgrid(grid_lat, grid_lon)\n","\n","    # Interpolate cell count data onto the grid\n","    grid_hab = griddata(\n","        points=(latitudes, longitudes),\n","        values=cell_counts,\n","        xi=(grid_lat, grid_lon),\n","        method='linear'\n","    )\n","\n","    # Plot the world map using geopandas\n","    world = gdf\n","\n","    # Create the plot with the world map as background\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    world.plot(ax=ax, color='lightgray')  # Plot the world map in light gray\n","\n","    # Plot the heatmap as contour\n","    contour = ax.contourf(grid_lon, grid_lat, grid_hab, levels=50, cmap='YlOrRd', alpha=0.7)\n","    plt.colorbar(contour, ax=ax, label=\"Cell Count (HAB Likelihood)\")\n","\n","    # Plot the data points on top\n","    ax.scatter(longitudes, latitudes, c='blue', s=10, label='Data Points', alpha=0.6)\n","\n","    # Set the title and labels\n","    ax.set_title(f\"HAB Heat Map: {state_name} - {month}/{year}\")\n","    ax.set_xlabel(\"Longitude\")\n","    ax.set_ylabel(\"Latitude\")\n","    ax.legend()\n","\n","    # Set the limits to zoom in on the U.S.\n","    ax.set_xlim(-82.8, -82.5)  # Longitude range for the U.S.\n","    ax.set_ylim(27.4, 27.8)     # Latitude range for the U.S.\n","\n","    plt.show()\n","\n","# Example usage:\n","plot_hab_heatmap_by_state_on_map(\"drive/MyDrive/Team15-Biointerphase/Dataset/(final)cleaned_habsos_data_v3.csv\", state_name=\"FL\", year=2013, month=9)\n"],"metadata":{"id":"b0nJenzdIXiK"},"execution_count":null,"outputs":[]}]}